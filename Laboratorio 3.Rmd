---
title: "Laboratorio 3"
output: html_document
date: '2022-08-22'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r message=FALSE, warning=FALSE}
library(ggplot2)
library(dplyr)
library(tidyverse)

#traemos el dataset

db<-read.csv('train.csv')
summary(db)

```

Para empezar, podemos ver que el contenido del dataset es completamente diferente a los que hemos trabajado anteriormente, como podemos ver todas las columnas siguien una misma estructura de pixeles, asi como que tambien cuentan con valores numericos, los cuales representan un valor dentro de los pixeles. 

## ANALISIS EXPLORATORIO: 

Para poder tener una idea mas clara de lo que tenemos en el dataset, haremos una representacion visual de los datos para comprenderlos mejor. 

```{r}
table(db$label)

str(db, list.len=ncol(db))
summary(db)
dim(db)
db$label[1:20]
ggplot(data = db) + geom_histogram(aes(x=label,fill=factor(label)),bins=10, position = "stack",alpha = 0.5)+theme(legend.position="none")+ scale_x_continuous(breaks = seq(0, 100, 1.))


```

```{r echo=FALSE}
porcentaje<-0.8
set.seed(123)
corte <- sample(nrow(db),nrow(db)*porcentaje)
train<-db[corte,]
train <- cbind(train[,1],train[,-1]/255.0)
test<-db[-corte,]
```

Dividimos el train y test del conjunto de datos y mostramos el head de train. 


```{r echo=FALSE}
head(train[1:10])
```
```{r echo=FALSE}
m = matrix(unlist(train[10,-1]),nrow = 28,byrow = T)
image(m,col=grey.colors(255))
```
```{r echo=FALSE}
rotate <- function(x) t(apply(x, 2, rev)) #rota la imagen
par(mfrow=c(2,3))
lapply(1:6, 
    function(x) image(
                    rotate(matrix(unlist(train[x,-1]),nrow = 28,byrow = T)),
                    col=grey.colors(255),
                    xlab=train[x,1]
                )
)
par(mfrow=c(1,1)) # set plot options back to default
```









## PARTE 2

```{r include=FALSE}
library("readxl")
library(keras)
library(tensorflow)
library(dplyr)
library(forecast)
library(ggplot2)
library(recipes)
library(lubridate)

```


Para la parte dos del laboratorio nos pedian utilizar parte del laboratorio anterior para poder trabajar, por eso, nosotros usamos los datos de importacion del laboratorio anterior

```{r}
impor<-read_excel("Importacion.xlsx")

```

Una vez hecha esta parte, empezamos a modificar los datos para que sea trabajable con el LSTM 

```{r}
fd <- impor[c('Fecha','Diesel')]
diesel_ts <- ts(fd$Diesel, start = c(2001, 1),frequency = 12)
s1<-diff(diesel_ts)
plot(s1)

```

Y como podemos observar obtenemos una grafica que nos muestra los datos de importacion de combustible Diesel desde el año 2001. 


Ahora debemos de normalizar la serie, esto con la finalidad de que el LSTM pueda ser mas efectivo, asi como tambien creamos una serie supervisada. 
```{r}
norm_s1<-scale(s1)

lgd <-c(rep(NA, 1),norm_s1[1:(length(norm_s1)-1)])
supervised <-as.data.frame(cbind(lgd,norm_s1))
colnames(supervised)<-c("x-1", "x")
supervised[is.na(supervised)]<-0
```


Ahora fraccionamos la serie, 60% para entrenamiento, 20% para validación y 20% para prueba
```{r}
entrenamiento<-round(0.6*length(s1))
val_test<-round(0.2*length(s1))
test<-tail(supervised, val_test)
supervised<-supervised %>% head(nrow(.)-val_test)
validation<-supervised %>% tail(val_test)
supervised<-head(supervised, nrow(supervised)-val_test)
#El train son los que quedan
train<-supervised
rm(supervised)


y_train <- train[,2]
x_train <- train[,1]
y_val <- validation[,2]
x_val <- validation[,1]
y_test <- test[,2]
x_test <- test[,1]



```


Y para poder trabajarlo, debemos de convertir a matrices: 
```{r}
paso <- 1
caracteristicas<-1 #es univariada
dim(x_train) <- c(length(x_train),paso,caracteristicas)
dim(y_train) <- c(length(y_train),caracteristicas)
dim(x_test) <- c(length(x_test),paso,caracteristicas)
dim(y_test) <- c(length(y_test),caracteristicas)
dim(x_val) <- c(length(x_val),paso,caracteristicas)
dim(y_val) <- c(length(y_val),caracteristicas)

```


Con todos estos pasos hechos, con la preparacion de la serie para el LSTM, ahora ya podemos crear el MODELO del LSTM, por lo cual, procederemos a crear el primer modelo: 

### MODELO #1

```{r}
lote = 1
unidades <- 1
modelo1 <-keras_model_sequential()
modelo1 %>% 
  layer_lstm(unidades, batch_input_shape=c(lote, paso, caracteristicas),
             stateful = T) %>% 
  layer_dense(units = 1)

summary(modelo1)
```


```{r}
modelo1 %>%
  compile(
    optimizer = 'rmsprop',
    loss = 'mse'
  )
```


Entrenamos el modelo y graficamos lo que llevamos al momento
```{r}
epocas <- 50
history <- modelo1 %>% fit(
  x = x_train,
  y = y_train,
  validation_data = list(x_val, y_val),
  batch_size = lote,
  epochs = epocas,
  shuffle = FALSE,
  verbose = 0
)

plot(history)
```


Evaluamos el modelo en sus diferentes partes, entrenamiento, validacion y prueba

```{r}
print("Entrenamiento")
modelo1 %>% evaluate(
  x = x_train,
  y = y_train
)
print("Validación")
modelo1 %>% evaluate(
  x = x_val,
  y = y_val
)
print("Prueba")
modelo1 %>% evaluate(
  x = x_test,
  y = y_test
)
```

Luego de esto, solo resta crear una prediccion para el modelo, con lo cual tenemos: 

```{r}
prediccion_fun <- function(data,modelo, batch_size,scale,center,dif=F, Series=NULL,n=1){
  prediccion <- numeric(length(data))
  if (dif==F){
    for(i in 1:length(data)){
      X = data[i]
      dim(X) = c(1,1,1)
      yhat = modelo %>% predict(X, batch_size=batch_size)
      # invert scaling
      yhat = yhat*scale+center
      # store
      prediccion[i] <- yhat
    }
  }else{
    for(i in 1:length(data)){
      X = data[i]
      dim(X) = c(1,1,1)
      yhat = modelo1 %>% predict(X, batch_size=batch_size)
      # invert scaling
      yhat = yhat*scale+center
      # invert differencing
      yhat  = yhat + Series[(n+i)]
      # store
      prediccion[i] <- yhat
    }
  }
  
  return(prediccion)
}

prediccion_val <- prediccion_fun(x_val,modelo1,1,attr(norm_s1,"scaled:scale"),
                                 attr(norm_s1,"scaled:center"),dif=T,s1,entrenamiento              
)
prediccion_test <- prediccion_fun(x_test,modelo1,1,attr(norm_s1,"scaled:scale"),
                                  attr(norm_s1,"scaled:center"),dif=T,s1,entrenamiento+val_test               
)


```


Y por ultimo, solo nos queda graficar el modelo para poder compararlo con los modelos de ARIMA.

```{r}
serie<-s1
serie_test<- tail(serie,val_test)
serie<-head(serie,length(serie)-val_test)
serie_val<-tail(serie,val_test)
serie<-head(serie,length(serie)-val_test)
serie_train <- serie


df_serie_total<-data.frame(pass=as.matrix(s1), date=zoo::as.Date(time(s1)))
df_serie_val<-data.frame(pass=prediccion_val, date=zoo::as.Date(time(serie_val)))
df_serie_test<-data.frame(pass=prediccion_test, date=zoo::as.Date(time(serie_test)))


df_serie_total$class <- 'real'
df_serie_val$class <- 'validacion'
df_serie_test$class <- 'prueba'

df_serie<-rbind(df_serie_total, df_serie_val,df_serie_test)
df_serie$class<-factor(df_serie$class,levels = c('real','validacion','prueba'))
ggplot(df_serie,aes(x = date, y = pass, colour = class)) +
  geom_line()

```


### MODELO #2

Para el modelo 2, usamos un LSTM mucho mas complejo, no el mas simple, para poder determinar si entre mas especificado, mejor sera el modelo. 

```{r}
unit_lstm1 <- 64
dropout_lstm1 <- 0.01
recurrent_dropout_lstm1 <- 0.01

unit_lstm2 <- 32
dropout_lstm2 <- 0.01
recurrent_dropout_lstm2 <- 0.01

timesteps=1

modelo2 <- keras_model_sequential()

modelo2 %>%
  
  # lstm1
  layer_lstm(
    name = "lstm1",
    units = unit_lstm1,
    input_shape = c(timesteps, 1),
    dropout = dropout_lstm1,
    recurrent_dropout = recurrent_dropout_lstm1,
    return_sequences = TRUE
  ) %>%
  
  # lstm2
  layer_lstm(
    name = "lstm2",
    units = unit_lstm2,
    dropout = dropout_lstm2,
    recurrent_dropout = recurrent_dropout_lstm2,
    return_sequences = FALSE
  ) %>%
  
  layer_dense(
    name = "output",
    units = 1
  )


modelo2 %>%
  compile(
    optimizer = "rmsprop",
    loss = "mse"
  )


summary(modelo2)

```


Luego de establecer, nuestras metricas y parametros para el modelo numero 2, por lo cual recreamos los pasos anteriores del modelo para crear un modelo entrenado y poder hacer una prediccion y una grafica. 

```{r include=FALSE}

# Se entrena el segundo modelo 
epocas <- 50
history <- modelo2 %>% fit(
  x = x_train,
  y = y_train,
  validation_data = list(x_val, y_val),
  batch_size = lote,
  epochs = epocas,
  shuffle = FALSE,
  verbose = 0
)


#Se evalua el nuevo modelo 
print("Entrenamiento")
modelo2 %>% evaluate(
  x = x_train,
  y = y_train
)

print("Validaciion")
modelo2 %>% evaluate(
  x = x_val,
  y = y_val
)

print("Pueba")
modelo2 %>% evaluate(
  x = x_test,
  y = y_test
)

```

Entonces, para el modelo numero 2, creamos las predicciones correspondientes: 

```{r}
prediccion_val_2 <- prediccion_fun(x_val,modelo2,1,attr(norm_s1,"scaled:scale"),
                                   attr(norm_s1,"scaled:center"),dif=T,s1,entrenamiento              
)
prediccion_test_2 <- prediccion_fun(x_test,modelo2,1,attr(norm_s1,"scaled:scale"),
                                    attr(norm_s1,"scaled:center"),dif=T,s1,entrenamiento+val_test               
)
```


Y por ultimo podemos crear una grafica del modelo recien hecho: 

```{r}
df_serie_val_2<-data.frame(pass=prediccion_val_2, date=zoo::as.Date(time(serie_val)))
df_serie_test_2<-data.frame(pass=prediccion_test_2, date=zoo::as.Date(time(serie_test)))


df_serie_total$class <- 'real'
df_serie_val_2$class <- 'validacion'
df_serie_test_2$class <- 'prueba'

df_serie_2<-rbind(df_serie_total, df_serie_val_2,df_serie_test_2)
df_serie$class<-factor(df_serie_2$class,levels = c('real','validacion','prueba'))
ggplot(df_serie,aes(x = date, y = pass, colour = class)) +
  geom_line()
```

Lo que podemos ver, ahora que ambos modelos estan completos y de manera grafica, podemos ver que realmente no existe una diferencia muy amplia entre ambas pero si son bastante acertadas al momento de predecir, ya que tanto para la grafica del modelo 1 como del modelo 2, la linea roja representa el dato original y la linea azul representa la que nosotros logramos crear, podemos ver que el desface que tiene es realmente corto, pero ahora nos queda determinar, si es mejor el LTSM o ARIMA, para lo cual traemos la grafica del laboratorio anterior:




## LSTM VS ARIMA 


[Modelo Arima](https://ibb.co/8dX885n)


Realmente, viendo ambas graficas, por lo que se puede ver es que si bien ambos son muy buenos que hacer las predicciones, pero sin embargo, el LSTM crea una prediccion mucho mas completa, como que se logra crear una prediccion mas acerptada pero porque abarca mucho mas que lo que puede ser el ARIMA, pero esto no todo es bueno, ya que por el mismo hecho que el LSTM crea un modelo y una prediccion mucho mas completa que lo hace ARIMA, eso mismo hace que sea un proceso mucho mas denso y extenso, mientras que el ARIMA es mucho mas facil de implementar y cuanta con una ejecucion mucho mas rapida, no cuenta con el mayor rango de dificultad. En conclusion, ambos son metodos muy exactos y precisos, pero dependiendo de lo que se quiera usar y para que se desee implementar, quizas el LSTM es uno de mayor fidelidad. 








